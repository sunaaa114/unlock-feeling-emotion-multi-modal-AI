{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45a61ff3",
   "metadata": {},
   "source": [
    "# 표정 특징 추출 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2c7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d77d07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1536461529392122462\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 3162032233914724620\n",
       " physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55edf9f3",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da3923b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               51600     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 734,800\n",
      "Trainable params: 734,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_dim = 400    # 특징 차원 수에 맞게 변경\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(feature_dim)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam')\n",
    "\n",
    "# 모델 요약 출력\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d170a9be",
   "metadata": {},
   "source": [
    "## 특징 추출 완성!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c810d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "network_saved = save_model(model, 'model/featureAI/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c9b6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 64, 64, 3], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"conv2d_input\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d\", \"trainable\": true, \"batch_input_shape\": [null, 64, 64, 3], \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d_1\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_2\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 128, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d_2\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 128, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 400, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.9.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('model/featureAI/featureAI.json', 'r') as json_file:\n",
    "    json_saved_model = json_file.read()\n",
    "json_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1437b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               51600     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 734,800\n",
      "Trainable params: 734,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_loaded = tf.keras.models.model_from_json(json_saved_model)\n",
    "network_loaded.load_weights('model/featureAI/weights.hdf5')\n",
    "network_loaded.compile(optimizer='Adam')\n",
    "network_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b9d0cf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 607ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# 이미지 50개만 선택해서 특징 추출\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "happyList = os.listdir('한국인 감정인식을 위한 복합 영상/Training1/기쁨')\n",
    "\n",
    "prediction = []\n",
    "for i in range(50):\n",
    "    image = cv2.imread('한국인 감정인식을 위한 복합 영상/Training1/기쁨/' + happyList[i])\n",
    "    roi = cv2.resize(image, (64, 64))\n",
    "    roi = roi / 255\n",
    "    \n",
    "    feature = model.predict(np.expand_dims(roi, axis=0))\n",
    "\n",
    "    prediction.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03184423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14744748,  0.01604744,  0.08844653,  0.02901251,  0.05955495,\n",
       "        -0.01233516, -0.02983252, -0.02208188, -0.04033911,  0.05752836,\n",
       "        -0.1147261 , -0.00025791, -0.08122497, -0.07894939, -0.0045892 ,\n",
       "         0.0151031 ,  0.03327703,  0.006045  , -0.03690238, -0.01442665,\n",
       "         0.03890117,  0.00524338, -0.01636473,  0.01741934, -0.06158079,\n",
       "        -0.11296864,  0.03223491, -0.00230795,  0.00798451, -0.02755954,\n",
       "         0.02555803,  0.14370099, -0.00533314,  0.05907374,  0.12331662,\n",
       "         0.03378845,  0.03845372,  0.06595925, -0.05906901, -0.07947154,\n",
       "         0.01964581, -0.01703541,  0.03860863,  0.0515989 ,  0.0247642 ,\n",
       "        -0.00204735, -0.0198562 , -0.04539012, -0.06064746, -0.02237985,\n",
       "         0.02845267,  0.0597506 , -0.0294268 , -0.00108065,  0.05312102,\n",
       "        -0.00988549, -0.08298852, -0.01707399,  0.00327575, -0.06556924,\n",
       "         0.00676116,  0.06503423, -0.05987858, -0.07182973,  0.04641211,\n",
       "        -0.04787118, -0.02736631,  0.1621202 ,  0.00757874,  0.00622453,\n",
       "        -0.04543095,  0.07254022, -0.03604472,  0.02260693, -0.07386424,\n",
       "         0.0129842 , -0.03976313, -0.17402354,  0.01620152, -0.02661269,\n",
       "         0.07136359,  0.0183517 ,  0.08454469, -0.08523239,  0.0392005 ,\n",
       "        -0.00192531, -0.01844113,  0.00213415,  0.02990285, -0.05997639,\n",
       "        -0.0354707 ,  0.03883403,  0.09064202, -0.00765471, -0.09778401,\n",
       "        -0.0078089 , -0.01705478,  0.08023828, -0.03762463, -0.018361  ,\n",
       "         0.02079974,  0.00826852, -0.00261946, -0.04364547, -0.00684579,\n",
       "        -0.04434249,  0.03560008, -0.03719317,  0.02910549, -0.05558916,\n",
       "        -0.03016489, -0.07776418,  0.07507092,  0.02602671,  0.00957385,\n",
       "         0.08457757, -0.10778799, -0.07883622, -0.06221075, -0.01320091,\n",
       "        -0.20202546, -0.04129481,  0.01643789, -0.03397464,  0.12173324,\n",
       "         0.11303104, -0.05942952,  0.00066071, -0.01356153,  0.05507511,\n",
       "        -0.0982845 , -0.01632306, -0.0252385 , -0.03399233,  0.07855599,\n",
       "         0.01461042,  0.02844039, -0.0725784 , -0.01928012,  0.00096906,\n",
       "        -0.00748122, -0.08920754, -0.07151381, -0.0043929 , -0.03507078,\n",
       "        -0.00171091,  0.10426966, -0.03379042,  0.0371552 ,  0.02631696,\n",
       "         0.02062326,  0.00727567,  0.07508106, -0.1215618 ,  0.0254382 ,\n",
       "         0.01620079, -0.0002874 , -0.07917997, -0.06952714,  0.04629929,\n",
       "        -0.00506814, -0.08610113, -0.02480624,  0.03110094, -0.03242803,\n",
       "         0.01044103,  0.07038525,  0.05368847, -0.06176344,  0.04113647,\n",
       "         0.05125524, -0.10832441,  0.03289385, -0.13776122, -0.02218981,\n",
       "         0.04969453, -0.1352677 ,  0.0409443 , -0.01830414, -0.05838709,\n",
       "         0.02583108,  0.03680874,  0.01299834,  0.00817252, -0.05722233,\n",
       "         0.01613108, -0.05245221, -0.03590298,  0.08501875, -0.01543595,\n",
       "         0.07624028, -0.08037943]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
